{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"E1.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMQFy0Drn5xm0+CBBcbDXbg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"HEezEVScSz1I","colab_type":"code","colab":{}},"source":["import argparse\n","import json\n","import importlib\n","import glob\n","import os"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"C7KVueMBx4k7","colab_type":"code","colab":{}},"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dropout, Dense\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.model_selection import train_test_split"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U3ghfm7QA3FD","colab_type":"text"},"source":["#Mount gdrive for folder access"]},{"cell_type":"code","metadata":{"id":"8pBHK07uA1X8","colab_type":"code","colab":{}},"source":["def gdrive_mount():\n","    from google.colab import drive\n","    drive.mount('/content/gdrive')\n","\n","gdrive_mount()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FfxgIlKYxZsS","colab_type":"text"},"source":["#Utilities\n"]},{"cell_type":"code","metadata":{"id":"I72avZKITAmE","colab_type":"code","colab":{}},"source":["def load_json(file_path):\n","    with open(file_path, 'r') as f:\n","        return json.load(f)\n","\n","\n","def save_json(data, target_file):\n","    with open(target_file, 'w') as f:\n","        json.dump(data, f, indent=2, sort_keys=True)\n","\n","\n","def load_config(config_file):\n","    config = load_json(config_file)\n","    return config\n","\n","\n","def random_crop(img, crop_dims):\n","    h, w = img.shape[0], img.shape[1]\n","    ch, cw = crop_dims[0], crop_dims[1]\n","    assert h >= ch, 'image height is less than crop height'\n","    assert w >= cw, 'image width is less than crop width'\n","    x = np.random.randint(0, w - cw + 1)\n","    y = np.random.randint(0, h - ch + 1)\n","    return img[y:(y+ch), x:(x+cw), :]\n","\n","\n","def random_horizontal_flip(img):\n","    assert len(img.shape) == 3, 'input tensor must have 3 dimensions (height, width, channels)'\n","    assert img.shape[2] == 3, 'image not in channels last format'\n","    if np.random.random() < 0.5:\n","        img = img.swapaxes(1, 0)\n","        img = img[::-1, ...]\n","        img = img.swapaxes(0, 1)\n","    return img\n","\n","\n","def load_image(img_file, target_size):\n","    return np.asarray(tf.keras.preprocessing.image.load_img(img_file, target_size=target_size))\n","\n","\n","def normalize_labels(labels):\n","    labels_np = np.array(labels)\n","    return labels_np / labels_np.sum()\n","\n","\n","def calc_mean_score(score_dist):\n","    score_dist = normalize_labels(score_dist)\n","    return (score_dist*np.arange(1, 11)).sum()\n","\n","\n","def ensure_dir_exists(dir):\n","    if not os.path.exists(dir):\n","        os.makedirs(dir)\n","\n","def ensure_file_exists(file):\n","  if not os.path.exists(file):\n","      os.touch(file)\n","\n","\n","def load_samples(samples_file):\n","    return load_json(samples_file)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UeR3coK_yCmn","colab_type":"text"},"source":["#Loss function"]},{"cell_type":"code","metadata":{"id":"82kdb_HTyC-h","colab_type":"code","colab":{}},"source":["def earth_movers_distance(y_true, y_pred):\n","    cdf_true = K.cumsum(y_true, axis=-1)\n","    cdf_pred = K.cumsum(y_pred, axis=-1)\n","    emd = K.sqrt(K.mean(K.square(cdf_true - cdf_pred), axis=-1))\n","    return K.mean(emd)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9MAYI9aCRC7J","colab_type":"text"},"source":["#Data Generator"]},{"cell_type":"code","metadata":{"id":"b3msqI_eRMg2","colab_type":"code","colab":{}},"source":["class TrainDataGenerator(tf.keras.utils.Sequence):\n","    '''inherits from Keras Sequence base object, allows to use multiprocessing in .fit_generator'''\n","    def __init__(self, samples, img_dir, batch_size, n_classes, basenet_preprocess, img_format,\n","                 img_load_dims=(256, 256), img_crop_dims=(224, 224), shuffle=True):\n","        self.samples = samples\n","        self.img_dir = img_dir\n","        self.batch_size = batch_size\n","        self.n_classes = n_classes\n","        self.basenet_preprocess = basenet_preprocess  # Keras basenet specific preprocessing function\n","        self.img_load_dims = img_load_dims  # dimensions that images get randomly cropped toload_dims  # dimensions that images get resized into when loaded\n","        self.img_crop_dims = img_crop_dims  # dimensions that images get randomly cropped to\n","        self.shuffle = shuffle\n","        self.img_format = img_format\n","        self.on_epoch_end()  # call ensures that samples are shuffled in first epoch if shuffle is set to True\n","\n","    def __len__(self):\n","        return int(np.ceil(len(self.samples) / self.batch_size))  # number of batches per epoch\n","\n","    def __getitem__(self, index):\n","        batch_indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]  # get batch indexes\n","        batch_samples = [self.samples[i] for i in batch_indexes]  # get batch samples\n","        X, y = self.__data_generator(batch_samples)\n","        return X, y\n","\n","    def on_epoch_end(self):\n","        self.indexes = np.arange(len(self.samples))\n","        if self.shuffle is True:\n","            np.random.shuffle(self.indexes)\n","\n","    def __data_generator(self, batch_samples):\n","        # initialize images and labels tensors for faster processing\n","        X = np.empty((len(batch_samples), *self.img_crop_dims, 3))\n","        y = np.empty((len(batch_samples), self.n_classes))\n","\n","        for i, sample in enumerate(batch_samples):\n","            # load and randomly augment image\n","            img_file = os.path.join(self.img_dir, '{}.{}'.format(sample['image_id'], self.img_format))\n","            img = load_image(img_file, self.img_load_dims)\n","            if img is not None:\n","                img = random_crop(img, self.img_crop_dims)\n","                img = random_horizontal_flip(img)\n","                X[i, ] = img\n","\n","            # normalize labels\n","            y[i, ] = normalize_labels(sample['label'])\n","\n","        # apply basenet specific preprocessing\n","        # input is 4D numpy array of RGB values within [0, 255]\n","        X = self.basenet_preprocess(X)\n","\n","        return X, y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EvFtRdoxXaMS","colab_type":"code","colab":{}},"source":["class TestDataGenerator(tf.keras.utils.Sequence):\n","    '''inherits from Keras Sequence base object, allows to use multiprocessing in .fit_generator'''\n","    def __init__(self, samples, img_dir, batch_size, n_classes, basenet_preprocess, img_format,\n","                 img_load_dims=(224, 224)):\n","        self.samples = samples\n","        self.img_dir = img_dir\n","        self.batch_size = batch_size\n","        self.n_classes = n_classes\n","        self.basenet_preprocess = basenet_preprocess  # Keras basenet specific preprocessing function\n","        self.img_load_dims = img_load_dims  # dimensions that images get resized into when loaded\n","        self.img_format = img_format\n","        self.on_epoch_end()  # call ensures that samples are shuffled in first epoch if shuffle is set to True\n","\n","    def __len__(self):\n","        return int(np.ceil(len(self.samples) / self.batch_size))  # number of batches per epoch\n","\n","    def __getitem__(self, index):\n","        batch_indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]  # get batch indexes\n","        batch_samples = [self.samples[i] for i in batch_indexes]  # get batch samples\n","        X, y = self.__data_generator(batch_samples)\n","        return X, y\n","\n","    def on_epoch_end(self):\n","        self.indexes = np.arange(len(self.samples))\n","\n","    def __data_generator(self, batch_samples):\n","        # initialize images and labels tensors for faster processing\n","        X = np.empty((len(batch_samples), *self.img_load_dims, 3))\n","        y = np.empty((len(batch_samples), self.n_classes))\n","\n","        for i, sample in enumerate(batch_samples):\n","            # load and randomly augment image\n","            img_file = os.path.join(self.img_dir, '{}.{}'.format(sample['image_id'], self.img_format))\n","            img = load_image(img_file, self.img_load_dims)\n","            if img is not None:\n","                X[i, ] = img\n","\n","            # normalize labels\n","            if sample.get('label') is not None:\n","                y[i, ] = normalize_labels(sample['label'])\n","\n","        # apply basenet specific preprocessing\n","        # input is 4D numpy array of RGB values within [0, 255]\n","        X = self.basenet_preprocess(X)\n","\n","        return X, y"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-LH5zcrfRNgh","colab_type":"text"},"source":["#Model Builder\n"]},{"cell_type":"code","metadata":{"id":"MmxRmrFLRhSo","colab_type":"code","colab":{}},"source":["class Nima:\n","    def __init__(self, base_model_name, n_classes=10, learning_rate=0.001, dropout_rate=0, loss=earth_movers_distance,\n","                 decay=0, weights='imagenet'):\n","        self.n_classes = n_classes\n","        self.base_model_name = base_model_name\n","        self.learning_rate = learning_rate\n","        self.dropout_rate = dropout_rate\n","        self.loss = loss\n","        self.decay = decay\n","        self.weights = weights\n","        self._get_base_module()\n","\n","    def _get_base_module(self):\n","        # import Keras base model module\n","        if self.base_model_name == 'InceptionV3':\n","            self.base_module = importlib.import_module('tensorflow.keras.applications.inception_v3')\n","        elif self.base_model_name == 'InceptionResNetV2':\n","            self.base_module = importlib.import_module('tensorflow.keras.applications.inception_resnet_v2')\n","        else:\n","            self.base_module = importlib.import_module('tensorflow.keras.applications.'+self.base_model_name.lower())\n","\n","    def build(self):\n","        # get base model class\n","        BaseCnn = getattr(self.base_module, self.base_model_name)\n","\n","        # load pre-trained model\n","        self.base_model = BaseCnn(input_shape=(224, 224, 3), weights=self.weights, include_top=False, pooling='avg')\n","\n","        # add dropout and dense layer\n","        x = Dropout(self.dropout_rate)(self.base_model.output)\n","        x = Dense(units=self.n_classes, activation='softmax')(x)\n","\n","        self.nima_model = Model(self.base_model.inputs, x)\n","\n","    def compile(self):\n","        self.nima_model.compile(optimizer=Adam(lr=self.learning_rate, decay=self.decay), loss=self.loss)\n","\n","    def preprocessing_function(self):\n","        return self.base_module.preprocess_input"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-Ktbm0U4RoZd","colab_type":"text"},"source":["#Train"]},{"cell_type":"code","metadata":{"id":"3vt5fUZRR8fB","colab_type":"code","colab":{}},"source":["def train(\n","    base_model_name,\n","    n_classes,\n","    samples,\n","    image_dir,\n","    batch_size,\n","    epochs_train_dense,\n","    epochs_train_all,\n","    learning_rate_dense,\n","    learning_rate_all,\n","    dropout_rate,\n","    weights_dir,\n","    log_dir,\n","    img_format='jpg',\n","    existing_weights=None,\n","    multiprocessing_data_load=False,\n","    num_workers_data_load=2,\n","    decay_dense=0,\n","    decay_all=0,\n","    **kwargs\n","):\n","\n","    # build NIMA model and load existing weights if they were provided in config\n","    nima = Nima(\n","        base_model_name, n_classes, learning_rate_dense, dropout_rate, decay=decay_dense\n","    )\n","    nima.build()\n","\n","    if existing_weights is not None:\n","        nima.nima_model.load_weights(existing_weights)\n","\n","    # split samples in train and validation set, and initialize data generators\n","    samples_train, samples_test = train_test_split(\n","        samples, test_size=0.05, shuffle=True, random_state=10207\n","    )\n","\n","    training_generator = TrainDataGenerator(\n","        samples_train,\n","        image_dir,\n","        batch_size,\n","        n_classes,\n","        nima.preprocessing_function(),\n","        img_format=img_format,\n","    )\n","\n","    validation_generator = TestDataGenerator(\n","        samples_test,\n","        image_dir,\n","        batch_size,\n","        n_classes,\n","        nima.preprocessing_function(),\n","        img_format=img_format,\n","    )\n","\n","    # initialize callbacks TensorBoard and ModelCheckpoint\n","    tensorboard = TensorBoard(\n","        log_dir=log_dir, update_freq='batch'\n","    )\n","\n","    model_save_name = (\n","        'weights_' + base_model_name.lower() + '_{epoch:02d}_{val_loss:.3f}.hdf5'\n","    )\n","    model_file_path = os.path.join(weights_dir, model_save_name)\n","    model_checkpointer = ModelCheckpoint(\n","        filepath=model_file_path,\n","        monitor='val_loss',\n","        verbose=1,\n","        save_best_only=True,\n","        save_weights_only=True,\n","    )\n","\n","    # start training only dense layers\n","    #freeze\n","    for layer in nima.base_model.layers:\n","        layer.trainable = False\n","\n","    nima.compile()\n","    nima.nima_model.summary()\n","\n","    nima.nima_model.fit_generator(\n","        generator=training_generator,\n","        validation_data=validation_generator,\n","        epochs=epochs_train_dense,\n","        verbose=1,\n","        use_multiprocessing=multiprocessing_data_load,\n","        workers=num_workers_data_load,\n","        max_queue_size=30,\n","        callbacks=[tensorboard, model_checkpointer],\n","    )\n","\n","    # start training all layers\n","    for layer in nima.base_model.layers:\n","        layer.trainable = True\n","\n","    nima.learning_rate = learning_rate_all\n","    nima.decay = decay_all\n","    nima.compile()\n","    nima.nima_model.summary()\n","\n","    nima.nima_model.fit_generator(\n","        generator=training_generator,\n","        validation_data=validation_generator,\n","        epochs=epochs_train_dense + epochs_train_all,\n","        initial_epoch=epochs_train_dense,\n","        verbose=1,\n","        use_multiprocessing=multiprocessing_data_load,\n","        workers=num_workers_data_load,\n","        max_queue_size=30,\n","        callbacks=[tensorboard, model_checkpointer],\n","    )\n","\n","    K.clear_session()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-HOMEEc5SPWW","colab_type":"text"},"source":["#Main for Train"]},{"cell_type":"code","metadata":{"id":"QomfpfUiUArI","colab_type":"code","colab":{}},"source":["IMAGE_DIR = '/content/gdrive/My Drive/TID2013/distorted_images'\n","\n","WEIGHTS_DIR = '/content/gdrive/My Drive/GC-IQA_Prism/IQA_Prism/weights/E1'\n","LOG_DIR = '/content/gdrive/My Drive/GC-IQA_Prism/IQA_Prism/logs/E1'\n","ensure_dir_exists(WEIGHTS_DIR)\n","ensure_dir_exists(LOG_DIR)\n","\n","CONFIG_DIR = '/content/gdrive/My Drive/GC-IQA_Prism/IQA_Prism/config'\n","CONFIG_FILE = os.path.join(CONFIG_DIR, 'config_technical_gpu.json')\n","config = load_config(CONFIG_FILE)\n","\n","SAMPLES_DIR = '/content/gdrive/My Drive/GC-IQA_Prism/IQA_Prism/labels/TID2013'\n","SAMPLES_FILE = os.path.join(SAMPLES_DIR, 'tid_labels_train.json')\n","samples = load_samples(SAMPLES_FILE)\n","\n","train(samples=samples, weights_dir=WEIGHTS_DIR, log_dir=LOG_DIR, image_dir=IMAGE_DIR, **config)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"341c7y43SBED","colab_type":"text"},"source":["#Predict"]},{"cell_type":"code","metadata":{"id":"EFOILpc1SN4x","colab_type":"code","colab":{}},"source":["def image_file_to_json(img_path):\n","    img_dir = os.path.dirname(img_path)\n","    img_id = os.path.basename(img_path).split('.')[0]\n","\n","    return img_dir, [{'image_id': img_id}]\n","\n","\n","def image_dir_to_json(img_dir, img_type='jpg'):\n","    img_paths = glob.glob(os.path.join(img_dir, '*.'+img_type))\n","\n","    samples = []\n","    for img_path in img_paths:\n","        img_id = os.path.basename(img_path).split('.')[0]\n","        samples.append({'image_id': img_id})\n","\n","    return samples\n","\n","\n","def predict(base_model_name, weights_file, image_source, predictions_file, img_format='jpg'):\n","    # load samples\n","    if os.path.isfile(image_source):\n","        image_dir, samples = image_file_to_json(image_source)\n","    else:\n","        image_dir = image_source\n","        samples = image_dir_to_json(image_dir, img_type='jpg')\n","\n","    # build model and load weights\n","    nima = Nima(base_model_name, weights=None)\n","    nima.build()\n","    nima.nima_model.load_weights(weights_file)\n","\n","    # initialize data generator\n","    data_generator = TestDataGenerator(samples, image_dir, 64, 10, nima.preprocessing_function(),\n","                                       img_format=img_format)\n","\n","    # get predictions\n","    predictions = nima.nima_model.predict_generator(data_generator, workers=8, use_multiprocessing=True, verbose=1)\n","\n","    # calc mean scores and add to samples\n","    for i, sample in enumerate(samples):\n","        sample['mean_score_prediction'] = calc_mean_score(predictions[i])\n","\n","    print(json.dumps(samples, indent=2))\n","\n","    if predictions_file is not None:\n","        save_json(samples, predictions_file)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1U0Vql1HUJrW","colab_type":"text"},"source":["#Main for predict"]},{"cell_type":"code","metadata":{"id":"WBV7s-uiULhu","colab_type":"code","colab":{}},"source":["BASE_MODEL_NAME = \"MobileNet\"\n","WEIGHTS_FILE = '/content/gdrive/My Drive/GC-IQA_Prism/IQA_Prism/weights/E1/weights_mobilenet_50_0.074.hdf5'\n","IMAGE_SOURCE = '/content/gdrive/My Drive/GC-IQA_Prism/IQA_Prism/test_images'\n","PREDICTIONS_FILE = '/content/gdrive/My Drive/GC-IQA_Prism/IQA_Prism/predictions/E1.json'\n","\n","ensure_file_exists(PREDICTIONS_FILE)\n","\n","predict(base_model_name=BASE_MODEL_NAME, weights_file=WEIGHTS_FILE, image_source=IMAGE_SOURCE, predictions_file=PREDICTIONS_FILE)"],"execution_count":0,"outputs":[]}]}