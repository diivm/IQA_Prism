{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"E1.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNbpDDe7AwWOHBsiZ302xqM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"HEezEVScSz1I","colab_type":"code","colab":{}},"source":["import argparse\n","import json\n","import importlib\n","import glob\n","import os"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"C7KVueMBx4k7","colab_type":"code","colab":{}},"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dropout, Dense\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.model_selection import train_test_split"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U3ghfm7QA3FD","colab_type":"text"},"source":["#Mount gdrive for folder access"]},{"cell_type":"code","metadata":{"id":"8pBHK07uA1X8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"outputId":"3f6d9772-3814-455b-de8b-0aac5e9c3f67","executionInfo":{"status":"ok","timestamp":1589980147467,"user_tz":-330,"elapsed":7107,"user":{"displayName":"Divyanshu Madan","photoUrl":"","userId":"02650825730649181464"}}},"source":["def gdrive_mount():\n","    from google.colab import drive\n","    drive.mount('/content/gdrive')\n","\n","gdrive_mount()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FfxgIlKYxZsS","colab_type":"text"},"source":["#Utilities\n"]},{"cell_type":"code","metadata":{"id":"I72avZKITAmE","colab_type":"code","colab":{}},"source":["def load_json(file_path):\n","    with open(file_path, 'r') as f:\n","        return json.load(f)\n","\n","\n","def save_json(data, target_file):\n","    with open(target_file, 'w') as f:\n","        json.dump(data, f, indent=2, sort_keys=True)\n","\n","\n","def load_config(config_file):\n","    config = load_json(config_file)\n","    return config\n","\n","\n","def random_crop(img, crop_dims):\n","    h, w = img.shape[0], img.shape[1]\n","    ch, cw = crop_dims[0], crop_dims[1]\n","    assert h >= ch, 'image height is less than crop height'\n","    assert w >= cw, 'image width is less than crop width'\n","    x = np.random.randint(0, w - cw + 1)\n","    y = np.random.randint(0, h - ch + 1)\n","    return img[y:(y+ch), x:(x+cw), :]\n","\n","\n","def random_horizontal_flip(img):\n","    assert len(img.shape) == 3, 'input tensor must have 3 dimensions (height, width, channels)'\n","    assert img.shape[2] == 3, 'image not in channels last format'\n","    if np.random.random() < 0.5:\n","        img = img.swapaxes(1, 0)\n","        img = img[::-1, ...]\n","        img = img.swapaxes(0, 1)\n","    return img\n","\n","\n","def load_image(img_file, target_size):\n","    return np.asarray(tf.keras.preprocessing.image.load_img(img_file, target_size=target_size))\n","\n","\n","def normalize_labels(labels):\n","    labels_np = np.array(labels)\n","    return labels_np / labels_np.sum()\n","\n","\n","def calc_mean_score(score_dist):\n","    score_dist = normalize_labels(score_dist)\n","    return (score_dist*np.arange(1, 11)).sum()\n","\n","\n","def ensure_dir_exists(dir):\n","    if not os.path.exists(dir):\n","        os.makedirs(dir)\n","\n","def ensure_file_exists(file):\n","  if not os.path.exists(file):\n","      os.touch(file)\n","\n","\n","def load_samples(samples_file):\n","    return load_json(samples_file)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UeR3coK_yCmn","colab_type":"text"},"source":["#Loss function"]},{"cell_type":"code","metadata":{"id":"82kdb_HTyC-h","colab_type":"code","colab":{}},"source":["def earth_movers_distance(y_true, y_pred):\n","    cdf_true = K.cumsum(y_true, axis=-1)\n","    cdf_pred = K.cumsum(y_pred, axis=-1)\n","    emd = K.sqrt(K.mean(K.square(cdf_true - cdf_pred), axis=-1))\n","    return K.mean(emd)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9MAYI9aCRC7J","colab_type":"text"},"source":["#Data Generator"]},{"cell_type":"code","metadata":{"id":"b3msqI_eRMg2","colab_type":"code","colab":{}},"source":["class TrainDataGenerator(tf.keras.utils.Sequence):\n","    '''inherits from Keras Sequence base object, allows to use multiprocessing in .fit_generator'''\n","    def __init__(self, samples, img_dir, batch_size, n_classes, basenet_preprocess, img_format,\n","                 img_load_dims=(256, 256), img_crop_dims=(224, 224), shuffle=True):\n","        self.samples = samples\n","        self.img_dir = img_dir\n","        self.batch_size = batch_size\n","        self.n_classes = n_classes\n","        self.basenet_preprocess = basenet_preprocess  # Keras basenet specific preprocessing function\n","        self.img_load_dims = img_load_dims  # dimensions that images get randomly cropped toload_dims  # dimensions that images get resized into when loaded\n","        self.img_crop_dims = img_crop_dims  # dimensions that images get randomly cropped to\n","        self.shuffle = shuffle\n","        self.img_format = img_format\n","        self.on_epoch_end()  # call ensures that samples are shuffled in first epoch if shuffle is set to True\n","\n","    def __len__(self):\n","        return int(np.ceil(len(self.samples) / self.batch_size))  # number of batches per epoch\n","\n","    def __getitem__(self, index):\n","        batch_indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]  # get batch indexes\n","        batch_samples = [self.samples[i] for i in batch_indexes]  # get batch samples\n","        X, y = self.__data_generator(batch_samples)\n","        return X, y\n","\n","    def on_epoch_end(self):\n","        self.indexes = np.arange(len(self.samples))\n","        if self.shuffle is True:\n","            np.random.shuffle(self.indexes)\n","\n","    def __data_generator(self, batch_samples):\n","        # initialize images and labels tensors for faster processing\n","        X = np.empty((len(batch_samples), *self.img_crop_dims, 3))\n","        y = np.empty((len(batch_samples), self.n_classes))\n","\n","        for i, sample in enumerate(batch_samples):\n","            # load and randomly augment image\n","            img_file = os.path.join(self.img_dir, '{}.{}'.format(sample['image_id'], self.img_format))\n","            img = load_image(img_file, self.img_load_dims)\n","            if img is not None:\n","                img = random_crop(img, self.img_crop_dims)\n","                img = random_horizontal_flip(img)\n","                X[i, ] = img\n","\n","            # normalize labels\n","            y[i, ] = normalize_labels(sample['label'])\n","\n","        # apply basenet specific preprocessing\n","        # input is 4D numpy array of RGB values within [0, 255]\n","        X = self.basenet_preprocess(X)\n","\n","        return X, y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EvFtRdoxXaMS","colab_type":"code","colab":{}},"source":["class TestDataGenerator(tf.keras.utils.Sequence):\n","    '''inherits from Keras Sequence base object, allows to use multiprocessing in .fit_generator'''\n","    def __init__(self, samples, img_dir, batch_size, n_classes, basenet_preprocess, img_format,\n","                 img_load_dims=(224, 224)):\n","        self.samples = samples\n","        self.img_dir = img_dir\n","        self.batch_size = batch_size\n","        self.n_classes = n_classes\n","        self.basenet_preprocess = basenet_preprocess  # Keras basenet specific preprocessing function\n","        self.img_load_dims = img_load_dims  # dimensions that images get resized into when loaded\n","        self.img_format = img_format\n","        self.on_epoch_end()  # call ensures that samples are shuffled in first epoch if shuffle is set to True\n","\n","    def __len__(self):\n","        return int(np.ceil(len(self.samples) / self.batch_size))  # number of batches per epoch\n","\n","    def __getitem__(self, index):\n","        batch_indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]  # get batch indexes\n","        batch_samples = [self.samples[i] for i in batch_indexes]  # get batch samples\n","        X, y = self.__data_generator(batch_samples)\n","        return X, y\n","\n","    def on_epoch_end(self):\n","        self.indexes = np.arange(len(self.samples))\n","\n","    def __data_generator(self, batch_samples):\n","        # initialize images and labels tensors for faster processing\n","        X = np.empty((len(batch_samples), *self.img_load_dims, 3))\n","        y = np.empty((len(batch_samples), self.n_classes))\n","\n","        for i, sample in enumerate(batch_samples):\n","            # load and randomly augment image\n","            img_file = os.path.join(self.img_dir, '{}.{}'.format(sample['image_id'], self.img_format))\n","            img = load_image(img_file, self.img_load_dims)\n","            if img is not None:\n","                X[i, ] = img\n","\n","            # normalize labels\n","            if sample.get('label') is not None:\n","                y[i, ] = normalize_labels(sample['label'])\n","\n","        # apply basenet specific preprocessing\n","        # input is 4D numpy array of RGB values within [0, 255]\n","        X = self.basenet_preprocess(X)\n","\n","        return X, y"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-LH5zcrfRNgh","colab_type":"text"},"source":["#Model Builder\n"]},{"cell_type":"code","metadata":{"id":"MmxRmrFLRhSo","colab_type":"code","colab":{}},"source":["class Nima:\n","    def __init__(self, base_model_name, n_classes=10, learning_rate=0.001, dropout_rate=0, loss=earth_movers_distance,\n","                 decay=0, weights='imagenet'):\n","        self.n_classes = n_classes\n","        self.base_model_name = base_model_name\n","        self.learning_rate = learning_rate\n","        self.dropout_rate = dropout_rate\n","        self.loss = loss\n","        self.decay = decay\n","        self.weights = weights\n","        self._get_base_module()\n","\n","    def _get_base_module(self):\n","        # import Keras base model module\n","        if self.base_model_name == 'InceptionV3':\n","            self.base_module = importlib.import_module('tensorflow.keras.applications.inception_v3')\n","        elif self.base_model_name == 'InceptionResNetV2':\n","            self.base_module = importlib.import_module('tensorflow.keras.applications.inception_resnet_v2')\n","        else:\n","            self.base_module = importlib.import_module('tensorflow.keras.applications.'+self.base_model_name.lower())\n","\n","    def build(self):\n","        # get base model class\n","        BaseCnn = getattr(self.base_module, self.base_model_name)\n","\n","        # load pre-trained model\n","        self.base_model = BaseCnn(input_shape=(224, 224, 3), weights=self.weights, include_top=False, pooling='avg')\n","\n","        # add dropout and dense layer\n","        x = Dropout(self.dropout_rate)(self.base_model.output)\n","        x = Dense(units=self.n_classes, activation='softmax')(x)\n","\n","        self.nima_model = Model(self.base_model.inputs, x)\n","\n","    def compile(self):\n","        self.nima_model.compile(optimizer=Adam(lr=self.learning_rate, decay=self.decay), loss=self.loss)\n","\n","    def preprocessing_function(self):\n","        return self.base_module.preprocess_input"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-Ktbm0U4RoZd","colab_type":"text"},"source":["#Train"]},{"cell_type":"code","metadata":{"id":"3vt5fUZRR8fB","colab_type":"code","colab":{}},"source":["def train(\n","    base_model_name,\n","    n_classes,\n","    samples,\n","    image_dir,\n","    batch_size,\n","    epochs_train_dense,\n","    epochs_train_all,\n","    learning_rate_dense,\n","    learning_rate_all,\n","    dropout_rate,\n","    weights_dir,\n","    log_dir,\n","    img_format='jpg',\n","    existing_weights=None,\n","    multiprocessing_data_load=False,\n","    num_workers_data_load=2,\n","    decay_dense=0,\n","    decay_all=0,\n","    **kwargs\n","):\n","\n","    # build NIMA model and load existing weights if they were provided in config\n","    nima = Nima(\n","        base_model_name, n_classes, learning_rate_dense, dropout_rate, decay=decay_dense\n","    )\n","    nima.build()\n","\n","    if existing_weights is not None:\n","        nima.nima_model.load_weights(existing_weights)\n","\n","    # split samples in train and validation set, and initialize data generators\n","    samples_train, samples_test = train_test_split(\n","        samples, test_size=0.05, shuffle=True, random_state=10207\n","    )\n","\n","    training_generator = TrainDataGenerator(\n","        samples_train,\n","        image_dir,\n","        batch_size,\n","        n_classes,\n","        nima.preprocessing_function(),\n","        img_format=img_format,\n","    )\n","\n","    validation_generator = TestDataGenerator(\n","        samples_test,\n","        image_dir,\n","        batch_size,\n","        n_classes,\n","        nima.preprocessing_function(),\n","        img_format=img_format,\n","    )\n","\n","    # initialize callbacks TensorBoard and ModelCheckpoint\n","    tensorboard = TensorBoard(\n","        log_dir=log_dir, update_freq='batch'\n","    )\n","\n","    model_save_name = (\n","        'weights_' + base_model_name.lower() + '_{epoch:02d}_{val_loss:.3f}.hdf5'\n","    )\n","    model_file_path = os.path.join(weights_dir, model_save_name)\n","    model_checkpointer = ModelCheckpoint(\n","        filepath=model_file_path,\n","        monitor='val_loss',\n","        verbose=1,\n","        save_best_only=True,\n","        save_weights_only=True,\n","    )\n","\n","    # start training only dense layers\n","    #freeze\n","    for layer in nima.base_model.layers:\n","        layer.trainable = False\n","\n","    nima.compile()\n","    nima.nima_model.summary()\n","\n","    nima.nima_model.fit_generator(\n","        generator=training_generator,\n","        validation_data=validation_generator,\n","        epochs=epochs_train_dense,\n","        verbose=1,\n","        use_multiprocessing=multiprocessing_data_load,\n","        workers=num_workers_data_load,\n","        max_queue_size=30,\n","        callbacks=[tensorboard, model_checkpointer],\n","    )\n","\n","    # start training all layers\n","    for layer in nima.base_model.layers:\n","        layer.trainable = True\n","\n","    nima.learning_rate = learning_rate_all\n","    nima.decay = decay_all\n","    nima.compile()\n","    nima.nima_model.summary()\n","\n","    nima.nima_model.fit_generator(\n","        generator=training_generator,\n","        validation_data=validation_generator,\n","        epochs=epochs_train_dense + epochs_train_all,\n","        initial_epoch=epochs_train_dense,\n","        verbose=1,\n","        use_multiprocessing=multiprocessing_data_load,\n","        workers=num_workers_data_load,\n","        max_queue_size=30,\n","        callbacks=[tensorboard, model_checkpointer],\n","    )\n","\n","    K.clear_session()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-HOMEEc5SPWW","colab_type":"text"},"source":["#Main for Train"]},{"cell_type":"code","metadata":{"id":"QomfpfUiUArI","colab_type":"code","outputId":"022d0607-9f7c-45cd-b327-1d3f8e7d3e62","executionInfo":{"status":"error","timestamp":1589980228752,"user_tz":-330,"elapsed":28931,"user":{"displayName":"Divyanshu Madan","photoUrl":"","userId":"02650825730649181464"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["IMAGE_DIR = '/content/gdrive/My Drive/TID2013/distorted_images'\n","\n","WEIGHTS_DIR = '/content/gdrive/My Drive/GC-IQA_Prism/IQA_Prism/weights/E1'\n","LOG_DIR = '/content/gdrive/My Drive/GC-IQA_Prism/IQA_Prism/logs/E1'\n","ensure_dir_exists(WEIGHTS_DIR)\n","ensure_dir_exists(LOG_DIR)\n","\n","CONFIG_DIR = '/content/gdrive/My Drive/GC-IQA_Prism/IQA_Prism/config'\n","CONFIG_FILE = os.path.join(CONFIG_DIR, 'config_technical_gpu.json')\n","config = load_config(CONFIG_FILE)\n","\n","SAMPLES_DIR = '/content/gdrive/My Drive/GC-IQA_Prism/IQA_Prism/labels/TID2013'\n","SAMPLES_FILE = os.path.join(SAMPLES_DIR, 'tid_labels_train.json')\n","samples = load_samples(SAMPLES_FILE)\n","\n","train(samples=samples, weights_dir=WEIGHTS_DIR, log_dir=LOG_DIR, image_dir=IMAGE_DIR, **config)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n","_________________________________________________________________\n","conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         \n","_________________________________________________________________\n","conv1 (Conv2D)               (None, 112, 112, 32)      864       \n","_________________________________________________________________\n","conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n","_________________________________________________________________\n","conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n","_________________________________________________________________\n","conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n","_________________________________________________________________\n","conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n","_________________________________________________________________\n","conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n","_________________________________________________________________\n","conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n","_________________________________________________________________\n","conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n","_________________________________________________________________\n","conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n","_________________________________________________________________\n","conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n","_________________________________________________________________\n","conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n","_________________________________________________________________\n","conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n","_________________________________________________________________\n","conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n","_________________________________________________________________\n","conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n","_________________________________________________________________\n","conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n","_________________________________________________________________\n","conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n","_________________________________________________________________\n","conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n","_________________________________________________________________\n","conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n","_________________________________________________________________\n","conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n","_________________________________________________________________\n","conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n","_________________________________________________________________\n","conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n","_________________________________________________________________\n","conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n","_________________________________________________________________\n","conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n","_________________________________________________________________\n","conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n","_________________________________________________________________\n","conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n","_________________________________________________________________\n","conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n","_________________________________________________________________\n","conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n","_________________________________________________________________\n","conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n","_________________________________________________________________\n","conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n","_________________________________________________________________\n","conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n","_________________________________________________________________\n","conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n","_________________________________________________________________\n","conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n","_________________________________________________________________\n","conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n","_________________________________________________________________\n","conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n","_________________________________________________________________\n","conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n","_________________________________________________________________\n","conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n","_________________________________________________________________\n","conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n","_________________________________________________________________\n","conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n","_________________________________________________________________\n","conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n","_________________________________________________________________\n","conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n","_________________________________________________________________\n","conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n","_________________________________________________________________\n","conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n","_________________________________________________________________\n","conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n","_________________________________________________________________\n","conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n","_________________________________________________________________\n","conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n","_________________________________________________________________\n","conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n","_________________________________________________________________\n","conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n","_________________________________________________________________\n","conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n","_________________________________________________________________\n","conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n","_________________________________________________________________\n","conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n","_________________________________________________________________\n","conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n","_________________________________________________________________\n","conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n","_________________________________________________________________\n","conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n","_________________________________________________________________\n","conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n","_________________________________________________________________\n","conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n","_________________________________________________________________\n","conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n","_________________________________________________________________\n","conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n","_________________________________________________________________\n","conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n","_________________________________________________________________\n","conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n","_________________________________________________________________\n","conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n","_________________________________________________________________\n","conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n","_________________________________________________________________\n","conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n","_________________________________________________________________\n","conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n","_________________________________________________________________\n","conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n","_________________________________________________________________\n","conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n","_________________________________________________________________\n","conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n","_________________________________________________________________\n","conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n","_________________________________________________________________\n","global_average_pooling2d (Gl (None, 1024)              0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 1024)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 10)                10250     \n","=================================================================\n","Total params: 3,239,114\n","Trainable params: 10,250\n","Non-trainable params: 3,228,864\n","_________________________________________________________________\n","WARNING:tensorflow:From <ipython-input-10-e4eeb5f72d8f>:88: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use Model.fit, which supports generators.\n","Epoch 1/25\n","WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n"],"name":"stdout"},{"output_type":"stream","text":["Process Keras_worker_ForkPoolWorker-4:\n","Process Keras_worker_ForkPoolWorker-3:\n","Process Keras_worker_ForkPoolWorker-5:\n","Process Keras_worker_ForkPoolWorker-8:\n","Traceback (most recent call last):\n","Traceback (most recent call last):\n","Process Keras_worker_ForkPoolWorker-6:\n","Process Keras_worker_ForkPoolWorker-1:\n","Process Keras_worker_ForkPoolWorker-2:\n","Process Keras_worker_ForkPoolWorker-7:\n","Traceback (most recent call last):\n","Traceback (most recent call last):\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n","    self.run()\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n","    self.run()\n","Traceback (most recent call last):\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 125, in worker\n","    put((job, i, result))\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 125, in worker\n","    put((job, i, result))\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 346, in put\n","    with self._wlock:\n","  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n","    result = (True, func(*args, **kwds))\n","  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 125, in worker\n","    put((job, i, result))\n","  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n","    result = (True, func(*args, **kwds))\n","  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n","    result = (True, func(*args, **kwds))\n","  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 347, in put\n","    self._writer.send_bytes(obj)\n","  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n","    result = (True, func(*args, **kwds))\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n","    return self._semlock.__enter__()\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\", line 662, in get_index\n","    return _SHARED_SEQUENCES[uid][i]\n","KeyboardInterrupt\n","  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n","    self._send_bytes(m[offset:offset + size])\n","  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 346, in put\n","    with self._wlock:\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\", line 662, in get_index\n","    return _SHARED_SEQUENCES[uid][i]\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\", line 662, in get_index\n","    return _SHARED_SEQUENCES[uid][i]\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\", line 662, in get_index\n","    return _SHARED_SEQUENCES[uid][i]\n","  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n","    result = (True, func(*args, **kwds))\n","  File \"<ipython-input-7-d325c0d0eb73>\", line 22, in __getitem__\n","    X, y = self.__data_generator(batch_samples)\n","  File \"<ipython-input-7-d325c0d0eb73>\", line 22, in __getitem__\n","    X, y = self.__data_generator(batch_samples)\n","  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n","    return self._semlock.__enter__()\n","  File \"<ipython-input-7-d325c0d0eb73>\", line 22, in __getitem__\n","    X, y = self.__data_generator(batch_samples)\n","  File \"<ipython-input-7-d325c0d0eb73>\", line 38, in __data_generator\n","    img = load_image(img_file, self.img_load_dims)\n","  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 398, in _send_bytes\n","    self._send(buf)\n","  File \"<ipython-input-7-d325c0d0eb73>\", line 22, in __getitem__\n","    X, y = self.__data_generator(batch_samples)\n","  File \"<ipython-input-7-d325c0d0eb73>\", line 38, in __data_generator\n","    img = load_image(img_file, self.img_load_dims)\n","KeyboardInterrupt\n","  File \"<ipython-input-7-d325c0d0eb73>\", line 38, in __data_generator\n","    img = load_image(img_file, self.img_load_dims)\n","  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n","    n = write(self._handle, buf)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\", line 662, in get_index\n","    return _SHARED_SEQUENCES[uid][i]\n","  File \"<ipython-input-5-de4c118b879b>\", line 37, in load_image\n","    return np.asarray(tf.keras.preprocessing.image.load_img(img_file, target_size=target_size))\n","  File \"<ipython-input-5-de4c118b879b>\", line 37, in load_image\n","    return np.asarray(tf.keras.preprocessing.image.load_img(img_file, target_size=target_size))\n","  File \"<ipython-input-7-d325c0d0eb73>\", line 38, in __data_generator\n","    img = load_image(img_file, self.img_load_dims)\n","KeyboardInterrupt\n","  File \"<ipython-input-5-de4c118b879b>\", line 37, in load_image\n","    return np.asarray(tf.keras.preprocessing.image.load_img(img_file, target_size=target_size))\n","  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py\", line 113, in load_img\n","    with open(path, 'rb') as f:\n","  File \"<ipython-input-5-de4c118b879b>\", line 37, in load_image\n","    return np.asarray(tf.keras.preprocessing.image.load_img(img_file, target_size=target_size))\n","KeyboardInterrupt\n","  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py\", line 113, in load_img\n","    with open(path, 'rb') as f:\n","  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py\", line 139, in load_img\n","    return img\n","  File \"<ipython-input-7-d325c0d0eb73>\", line 22, in __getitem__\n","    X, y = self.__data_generator(batch_samples)\n","  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py\", line 114, in load_img\n","    img = pil_image.open(io.BytesIO(f.read()))\n","  File \"<ipython-input-7-d325c0d0eb73>\", line 49, in __data_generator\n","    X = self.basenet_preprocess(X)\n","KeyboardInterrupt\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/applications/mobilenet.py\", line 453, in preprocess_input\n","    return imagenet_utils.preprocess_input(x, data_format=data_format, mode='tf')\n","KeyboardInterrupt\n","KeyboardInterrupt\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/applications/imagenet_utils.py\", line 107, in preprocess_input\n","    x, data_format=data_format, mode=mode)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/applications/imagenet_utils.py\", line 183, in _preprocess_numpy_input\n","    x -= 1.\n","KeyboardInterrupt\n"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-c9677c03c442>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAMPLES_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mWEIGHTS_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLOG_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIMAGE_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-10-e4eeb5f72d8f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(base_model_name, n_classes, samples, image_dir, batch_size, epochs_train_dense, epochs_train_all, learning_rate_dense, learning_rate_all, dropout_rate, weights_dir, log_dir, img_format, existing_weights, multiprocessing_data_load, num_workers_data_load, decay_dense, decay_all, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_workers_data_load\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_checkpointer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     )\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1477\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m   @deprecation.deprecated(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"341c7y43SBED","colab_type":"text"},"source":["#Predict"]},{"cell_type":"code","metadata":{"id":"EFOILpc1SN4x","colab_type":"code","colab":{}},"source":["def image_file_to_json(img_path):\n","    img_dir = os.path.dirname(img_path)\n","    img_id = os.path.basename(img_path).split('.')[0]\n","\n","    return img_dir, [{'image_id': img_id}]\n","\n","\n","def image_dir_to_json(img_dir, img_type='jpg'):\n","    img_paths = glob.glob(os.path.join(img_dir, '*.'+img_type))\n","\n","    samples = []\n","    for img_path in img_paths:\n","        img_id = os.path.basename(img_path).split('.')[0]\n","        samples.append({'image_id': img_id})\n","\n","    return samples\n","\n","\n","def predict(base_model_name, weights_file, image_source, predictions_file, img_format='jpg'):\n","    # load samples\n","    if os.path.isfile(image_source):\n","        image_dir, samples = image_file_to_json(image_source)\n","    else:\n","        image_dir = image_source\n","        samples = image_dir_to_json(image_dir, img_type='jpg')\n","\n","    # build model and load weights\n","    nima = Nima(base_model_name, weights=None)\n","    nima.build()\n","    nima.nima_model.load_weights(weights_file)\n","\n","    # initialize data generator\n","    data_generator = TestDataGenerator(samples, image_dir, 64, 10, nima.preprocessing_function(),\n","                                       img_format=img_format)\n","\n","    # get predictions\n","    predictions = nima.nima_model.predict_generator(data_generator, workers=8, use_multiprocessing=True, verbose=1)\n","\n","    # calc mean scores and add to samples\n","    for i, sample in enumerate(samples):\n","        sample['mean_score_prediction'] = calc_mean_score(predictions[i])\n","\n","    print(json.dumps(samples, indent=2))\n","\n","    if predictions_file is not None:\n","        save_json(samples, predictions_file)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1U0Vql1HUJrW","colab_type":"text"},"source":["#Main for predict"]},{"cell_type":"code","metadata":{"id":"WBV7s-uiULhu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":472},"outputId":"660d120d-993f-4f49-f747-6890cd522694","executionInfo":{"status":"ok","timestamp":1589980239830,"user_tz":-330,"elapsed":4796,"user":{"displayName":"Divyanshu Madan","photoUrl":"","userId":"02650825730649181464"}}},"source":["BASE_MODEL_NAME = \"MobileNet\"\n","WEIGHTS_FILE = '/content/gdrive/My Drive/GC-IQA_Prism/IQA_Prism/weights/E1/weights_mobilenet_50_0.074.hdf5'\n","IMAGE_SOURCE = '/content/gdrive/My Drive/GC-IQA_Prism/IQA_Prism/test_images'\n","PREDICTIONS_FILE = '/content/gdrive/My Drive/GC-IQA_Prism/IQA_Prism/predictions/E1.json'\n","\n","ensure_file_exists(PREDICTIONS_FILE)\n","\n","predict(base_model_name=BASE_MODEL_NAME, weights_file=WEIGHTS_FILE, image_source=IMAGE_SOURCE, predictions_file=PREDICTIONS_FILE)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-14-9f7b9eace02d>:37: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use Model.predict, which supports generators.\n","WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n","WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n","1/1 [==============================] - 0s 64ms/step\n","[\n","  {\n","    \"image_id\": \"42041\",\n","    \"mean_score_prediction\": 4.103508848696947\n","  },\n","  {\n","    \"image_id\": \"42044\",\n","    \"mean_score_prediction\": 3.919870112091303\n","  },\n","  {\n","    \"image_id\": \"42042\",\n","    \"mean_score_prediction\": 4.849147483706474\n","  },\n","  {\n","    \"image_id\": \"42040\",\n","    \"mean_score_prediction\": 3.5831059627234936\n","  },\n","  {\n","    \"image_id\": \"42039\",\n","    \"mean_score_prediction\": 3.843812245875597\n","  }\n","]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ppp_cqckIkeu","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}