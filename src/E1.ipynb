{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"E1.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMrp1ngJ07bKhrmn0qin4Ab"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"bQFmkokLmM84","colab_type":"text"},"source":["# Imports"]},{"cell_type":"code","metadata":{"id":"HEezEVScSz1I","colab_type":"code","colab":{}},"source":["import argparse\n","import json\n","import importlib\n","import glob\n","import os"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"C7KVueMBx4k7","colab_type":"code","colab":{}},"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dropout, Dense\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.model_selection import train_test_split"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U3ghfm7QA3FD","colab_type":"text"},"source":["# Mount gdrive for data access\n","\n","- This whole project, including the datasets, is maintained on Google Drive for ease of access while using Colab. \n","- Thus it is needed to mount the drive for use as a target location for I/O operations."]},{"cell_type":"code","metadata":{"id":"8pBHK07uA1X8","colab_type":"code","colab":{}},"source":["def gdrive_mount():\n","    from google.colab import drive\n","    drive.mount('/content/gdrive')\n","\n","gdrive_mount()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FfxgIlKYxZsS","colab_type":"text"},"source":["# Utilities\n","\n"," - Utilities functions for ease of use.\n"," - Image based functions such as `random_crop`, `random_horizontal_flip` are used for data augmentation purposes while generating Training data.\n"," - Label based functions such as `normalize_labels` and `calc_mean_score` are used for statistical purposes for input image labels (rating distributions)."]},{"cell_type":"code","metadata":{"id":"I72avZKITAmE","colab_type":"code","colab":{}},"source":["def load_json(file_path):\n","    with open(file_path, 'r') as f:\n","        return json.load(f)\n","\n","\n","def save_json(data, target_file):\n","    with open(target_file, 'w') as f:\n","        json.dump(data, f, indent=2, sort_keys=True)\n","\n","\n","def load_config(config_file):\n","    config = load_json(config_file)\n","    return config\n","\n","\n","def random_crop(img, crop_dims):\n","    h, w = img.shape[0], img.shape[1]\n","    ch, cw = crop_dims[0], crop_dims[1]\n","    assert h >= ch, 'image height is less than crop height'\n","    assert w >= cw, 'image width is less than crop width'\n","    x = np.random.randint(0, w - cw + 1)\n","    y = np.random.randint(0, h - ch + 1)\n","    return img[y:(y+ch), x:(x+cw), :]\n","\n","\n","def random_horizontal_flip(img):\n","    assert len(img.shape) == 3, 'input tensor must have 3 dimensions (height, width, channels)'\n","    assert img.shape[2] == 3, 'image not in channels last format'\n","    if np.random.random() < 0.5:\n","        img = img.swapaxes(1, 0)\n","        img = img[::-1, ...]\n","        img = img.swapaxes(0, 1)\n","    return img\n","\n","\n","def load_image(img_file, target_size):\n","    return np.asarray(tf.keras.preprocessing.image.load_img(img_file, target_size=target_size))\n","\n","\n","def normalize_labels(labels):\n","    labels_np = np.array(labels)\n","    return labels_np / labels_np.sum()\n","\n","\n","def calc_mean_score(score_dist):\n","    score_dist = normalize_labels(score_dist)\n","    return (score_dist*np.arange(1, 11)).sum()\n","\n","\n","def ensure_dir_exists(dir):\n","    if not os.path.exists(dir):\n","        os.makedirs(dir)\n","\n","\n","def ensure_file_exists(file):\n","  if not os.path.exists(file):\n","      os.touch(file)\n","\n","\n","def load_samples(samples_file):\n","    return load_json(samples_file)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UeR3coK_yCmn","colab_type":"text"},"source":["# Loss function\n","\n","The special feature of NIMA is the use of the Earth Mover’s Loss (EML) as the loss function, which differs from the Categorical Cross Entropy (CCE) loss generally applied in Deep Learning classification tasks. The EML can be understood as the amount of “earth” that needs to be moved to make two probability distributions equal. A useful attribute of this loss function is that it captures the inherent order of the classes.\n","\n","For example, in our scenario, the scores 4, 5, and 6 are more related than 1, 5, and 10. In other words, **we want to punish a prediction of 4 more if the true score is 10 than when the true score is 5.** CCE does not capture this relationship, which is often not required in object classification tasks (e.g. misclassifying a tree as a dog is as bad as classifying it as a cat).\n","\n","![Earth Mover's Distance](https://devblogs.nvidia.com/wp-content/uploads/2018/10/pastedImage0-3-1024x253.png)\n","\n","_Image source: https://devblogs.nvidia.com/deep-learning-hotel-aesthetics-photos/_\n"]},{"cell_type":"markdown","metadata":{"id":"lBQKGdsn3zcq","colab_type":"text"},"source":["$$EMD(p, \\hat{p})=\\bigg(\\frac{1}{N}\\sum_{k=1}^{N} {|CDF_{p}(k)-CDF_{\\hat p}(k)|}^r\\bigg)^{1/r}$$\n","\n","$p: \\textit{ground truth probability mass functions}$\n","\n","$\\hat{p}: \\textit{estimated probability mass functions}$\n","\n","$N: \\textit{number of ordered classes}$\n","\n","$CDF_p(k): \\textit{cumulative distribution function as} \\sum_{i=1}^{k}{p_{s_{i}}}$\n","\n","$r: \\textit{r-norm}$\n","\n","***\n","\n","$r = 2 \\textit{ to penalize the Euclidean distance between the\n","CDFs. It allows easier optimization when working with\n","gradient descent.}$\n"]},{"cell_type":"code","metadata":{"id":"82kdb_HTyC-h","colab_type":"code","colab":{}},"source":["def earth_movers_distance(y_true, y_pred):\n","    cdf_true = K.cumsum(y_true, axis=-1)\n","    cdf_pred = K.cumsum(y_pred, axis=-1)\n","    emd = K.sqrt(K.mean(K.square(cdf_true - cdf_pred), axis=-1))\n","    return K.mean(emd)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9MAYI9aCRC7J","colab_type":"text"},"source":["# Data Generator\n","\n","- Every `tf.keras.utils.Sequence` must implement the `__getitem__` and the `__len__` methods.\n","- The method `__getitem__` should return a complete batch.\n","- The method `on_epoch_end` is used to modify the dataset between epochs.\n","- The method `__data_generator` generates an array of `image, label` pair for enumerated pairs in `batch_samples`, after performing image augmentation on every image and `basenet_preprocess` on the generated image array."]},{"cell_type":"code","metadata":{"id":"b3msqI_eRMg2","colab_type":"code","colab":{}},"source":["class TrainDataGenerator(tf.keras.utils.Sequence):\n","    '''inherits from Keras Sequence base object, allows to use multiprocessing in .fit_generator'''\n","    def __init__(self, samples, img_dir, batch_size, n_classes, basenet_preprocess, img_format,\n","                 img_load_dims=(256, 256), img_crop_dims=(224, 224), shuffle=True):\n","        self.samples = samples\n","        self.img_dir = img_dir\n","        self.batch_size = batch_size\n","        self.n_classes = n_classes\n","        self.basenet_preprocess = basenet_preprocess  # Keras basenet specific preprocessing function\n","        self.img_load_dims = img_load_dims  # dimensions that images get resized into when loaded\n","        self.img_crop_dims = img_crop_dims  # dimensions that images get randomly cropped to\n","        self.shuffle = shuffle\n","        self.img_format = img_format\n","        self.on_epoch_end()  # call ensures that samples are shuffled in first epoch if shuffle is set to True\n","\n","    def __len__(self):\n","        return int(np.ceil(len(self.samples) / self.batch_size))  # number of batches per epoch\n","\n","    def __getitem__(self, index):\n","        batch_indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]  # get batch indexes\n","        batch_samples = [self.samples[i] for i in batch_indexes]  # get batch samples\n","        X, y = self.__data_generator(batch_samples)\n","        return X, y\n","\n","    def on_epoch_end(self):\n","        self.indexes = np.arange(len(self.samples))\n","        if self.shuffle is True:\n","            np.random.shuffle(self.indexes)\n","\n","    def __data_generator(self, batch_samples):\n","        # initialize images and labels tensors for faster processing\n","        X = np.empty((len(batch_samples), *self.img_crop_dims, 3))\n","        y = np.empty((len(batch_samples), self.n_classes))\n","\n","        for i, sample in enumerate(batch_samples):\n","            # load and randomly augment image\n","            img_file = os.path.join(self.img_dir, '{}.{}'.format(sample['image_id'], self.img_format))\n","            img = load_image(img_file, self.img_load_dims)\n","            if img is not None:\n","                img = random_crop(img, self.img_crop_dims)\n","                img = random_horizontal_flip(img)\n","                X[i, ] = img\n","\n","            # normalize labels\n","            y[i, ] = normalize_labels(sample['label'])\n","\n","        # apply basenet specific preprocessing\n","        # input is 4D numpy array of RGB values within [0, 255]\n","        X = self.basenet_preprocess(X)\n","\n","        return X, y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EvFtRdoxXaMS","colab_type":"code","colab":{}},"source":["class TestDataGenerator(tf.keras.utils.Sequence):\n","    '''inherits from Keras Sequence base object, allows to use multiprocessing in .fit_generator'''\n","    def __init__(self, samples, img_dir, batch_size, n_classes, basenet_preprocess, img_format,\n","                 img_load_dims=(224, 224)):\n","        self.samples = samples\n","        self.img_dir = img_dir\n","        self.batch_size = batch_size\n","        self.n_classes = n_classes\n","        self.basenet_preprocess = basenet_preprocess  # Keras basenet specific preprocessing function\n","        self.img_load_dims = img_load_dims  # dimensions that images get resized into when loaded\n","        self.img_format = img_format\n","        self.on_epoch_end()  # call ensures that samples are shuffled in first epoch if shuffle is set to True\n","\n","    def __len__(self):\n","        return int(np.ceil(len(self.samples) / self.batch_size))  # number of batches per epoch\n","\n","    def __getitem__(self, index):\n","        batch_indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]  # get batch indexes\n","        batch_samples = [self.samples[i] for i in batch_indexes]  # get batch samples\n","        X, y = self.__data_generator(batch_samples)\n","        return X, y\n","\n","    def on_epoch_end(self):\n","        self.indexes = np.arange(len(self.samples))\n","\n","    def __data_generator(self, batch_samples):\n","        # initialize images and labels tensors for faster processing\n","        X = np.empty((len(batch_samples), *self.img_load_dims, 3))\n","        y = np.empty((len(batch_samples), self.n_classes))\n","\n","        for i, sample in enumerate(batch_samples):\n","            # load and randomly augment image\n","            img_file = os.path.join(self.img_dir, '{}.{}'.format(sample['image_id'], self.img_format))\n","            img = load_image(img_file, self.img_load_dims)\n","            if img is not None:\n","                X[i, ] = img\n","\n","            # normalize labels\n","            if sample.get('label') is not None:\n","                y[i, ] = normalize_labels(sample['label'])\n","\n","        # apply basenet specific preprocessing\n","        # input is 4D numpy array of RGB values within [0, 255]\n","        X = self.basenet_preprocess(X)\n","\n","        return X, y"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-LH5zcrfRNgh","colab_type":"text"},"source":["# Model Builder\n","\n","- The method `_get_base_module` imports the base model from the Keras Applications. They are canned architectures with pre-trained weights.\n","- The method `build` is used to specify the architecture of network. The method `keras.applications.<model_name>` (`BaseCnn` in this case) can have following parameters:\n","  - `include_top`:\twhether to include the fully-connected layer at the top of the network.\n","  - `weights`:\tone of `None` (random initialization), `'imagenet'` (pre-training on ImageNet), or the path to the weights file to be loaded.\n","  - `input_tensor`:\toptional Keras tensor (i.e. output of `layers.Input()`) to use as image input for the model.\n","  - `input_shape`:\toptional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (299, 299, 3) (with 'channels_last' data format) or (3, 299, 299) (with 'channels_first' data format). It should have exactly 3 inputs channels, and width and height should be no smaller than 75. E.g. (150, 150, 3) would be one valid value.\n","  - `pooling`:\tOptional pooling mode for feature extraction when include_top is False.\n","     - `None`: means that the output of the model will be the 4D tensor output of the last convolutional block.\n","     - `'avg'`: means that global average pooling will be applied to the output of the last convolutional block, and thus the output of the model will be a 2D tensor.\n","     - `'max'`: means that global max pooling will be applied.\n","  - `classes`:\toptional number of classes to classify images into, only to be specified if include_top is True, and if no weights argument is specified.\n","  - `classifier_activation`:\tA str or callable. The activation function to use on the \"top\" layer. Ignored unless include_top=True. Set classifier_activation=None to return the logits of the \"top\" layer.\n"]},{"cell_type":"code","metadata":{"id":"MmxRmrFLRhSo","colab_type":"code","colab":{}},"source":["class Nima:\n","    def __init__(self, base_model_name, n_classes=10, learning_rate=0.001, dropout_rate=0, loss=earth_movers_distance,\n","                 decay=0, weights='imagenet'):\n","        self.n_classes = n_classes\n","        self.base_model_name = base_model_name\n","        self.learning_rate = learning_rate\n","        self.dropout_rate = dropout_rate\n","        self.loss = loss\n","        self.decay = decay\n","        self.weights = weights\n","        self._get_base_module()\n","\n","    def _get_base_module(self):\n","        # import Keras base model module\n","        if self.base_model_name == 'InceptionV3':\n","            self.base_module = importlib.import_module('tensorflow.keras.applications.inception_v3')\n","        elif self.base_model_name == 'InceptionResNetV2':\n","            self.base_module = importlib.import_module('tensorflow.keras.applications.inception_resnet_v2')\n","        else:\n","            self.base_module = importlib.import_module('tensorflow.keras.applications.'+self.base_model_name.lower())\n","\n","    def build(self):\n","        # get base model class\n","        BaseCnn = getattr(self.base_module, self.base_model_name)\n","\n","        # load pre-trained model\n","        self.base_model = BaseCnn(input_shape=(224, 224, 3), weights=self.weights, include_top=False, pooling='avg')\n","\n","        # add dropout and dense layer\n","        x = Dropout(self.dropout_rate)(self.base_model.output)\n","        x = Dense(units=self.n_classes, activation='softmax')(x)\n","\n","        self.nima_model = Model(self.base_model.inputs, x)\n","\n","    def compile(self):\n","        self.nima_model.compile(optimizer=Adam(lr=self.learning_rate, decay=self.decay), loss=self.loss)\n","\n","    def preprocessing_function(self):\n","        return self.base_module.preprocess_input"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-Ktbm0U4RoZd","colab_type":"text"},"source":["# Train\n","\n","- The method `ModelCheckpoint` can have the following parameters:\n","  - `filepath`\n","  - `monitor`: quantity to monitor.\n","  - `verbose`: verbose mode, 0 or 1.\n","  - `save_best_only`:\tif `save_best_only=True`, the latest best model according to the quantity monitored will not be overwritten. If filepath doesn't contain formatting options like `{epoch}` then filepath will be overwritten by each new better model.\n","  - `mode`:\tone of `{auto, min, max}`. If `save_best_only=True`, the decision to overwrite the current save file is made based on either the maximization or the minimization of the monitored quantity. For `val_acc`, this should be `max`, for `val_loss` this should be `min`, etc. In `auto` mode, the direction is automatically inferred from the name of the monitored quantity.\n","  - `save_weights_only`:\tif `True`, then only the model's weights will be saved, else the full model is saved.\n","  - `save_freq`:\t`'epoch'` or integer. When using `'epoch'`, the callback saves the model after each epoch. When using integer, the callback saves the model at end of this many batches.\n","\n","- The method `fit_generator` is deprecated and needs to be replaced with `fit`. It can have the following parameters:\n","  - `generator`\n","  - `steps_per_epoch`: Integer or `None`. Total number of steps (batches of samples) before declaring one epoch finished and starting the next epoch. \n","  - `epochs`: Integer. Number of epochs to train the model. An epoch is an iteration over the entire x and y data provided. Note that in conjunction with initial_epoch, epochs is to be understood as \"final epoch\". The model is not trained for a number of iterations given by epochs, but merely until the epoch of index epochs is reached.\n","  - `verbose`: 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch.\n","  - `callbacks`: List of keras.callbacks.Callback instances. List of callbacks to apply during training.\n","  - `validation_data`: Data on which to evaluate the loss and any model metrics at the end of each epoch. The model will not be trained on this data. validation_data will override validation_split. validation_data could be:\n","    - `tuple (x_val, y_val)` of Numpy arrays or tensors\n","    - `tuple (x_val, y_val, val_sample_weights)` of Numpy arrays\n","    - `dataset`\n","  - `validation_steps`: Only relevant if `validation_data` is provided and is a tf.data dataset. Total number of steps (batches of samples) to draw before stopping when performing validation at the end of every epoch. If `validation_steps` is None, validation will run until the validation_data dataset is exhausted. In the case of an infinitely repeated dataset, it will run into an infinite loop. If `validation_steps` is specified and only part of the dataset will be consumed, the evaluation will start from the beginning of the dataset at each epoch. This ensures that the same validation samples are used every time.\n","  - `validation_freq`: Only relevant if validation data is provided. Integer or collections_abc.Container instance (e.g. list, tuple, etc.). If an integer, specifies how many training epochs to run before a new validation run is performed, e.g. validation_freq=2 runs validation every 2 epochs. If a Container, specifies the epochs on which to run validation, e.g. validation_freq=[1, 2, 10] runs validation at the end of the 1st, 2nd, and 10th epochs.\n","  - `class_weight`: Optional dictionary mapping class indices (integers) to a weight (float) value, used for weighting the loss function (during training only). This can be useful to tell the model to \"pay more attention\" to samples from an under-represented class.\n","  - `max_queue_size`: Integer. Used for generator or keras.utils.Sequence input only. Maximum size for the generator queue. If unspecified, max_queue_size will default to 10.\n","  - `workers`: Integer. Used for generator or keras.utils.Sequence input only. Maximum number of processes to spin up when using process-based threading. If unspecified, workers will default to 1. If 0, will execute the generator on the main thread.\n","  - `use_multiprocessing`: Boolean. Used for generator or keras.utils.Sequence input only. If True, use process-based threading. If unspecified, use_multiprocessing will default to False. Note that because this implementation relies on multiprocessing, you should not pass non-picklable arguments to the generator as they can't be passed easily to children processes.\n","  - `shuffle`: Boolean (whether to shuffle the training data before each epoch) or str (for 'batch').\n","  - `initial_epoch`: Integer. Epoch at which to start training (useful for resuming a previous training run).\n"]},{"cell_type":"code","metadata":{"id":"3vt5fUZRR8fB","colab_type":"code","colab":{}},"source":["def train(\n","    base_model_name,\n","    n_classes,\n","    samples,\n","    image_dir,\n","    batch_size,\n","    epochs_train_dense,\n","    epochs_train_all,\n","    learning_rate_dense,\n","    learning_rate_all,\n","    dropout_rate,\n","    weights_dir,\n","    log_dir,\n","    img_format='jpg',\n","    existing_weights=None,\n","    multiprocessing_data_load=False,\n","    num_workers_data_load=2,\n","    decay_dense=0,\n","    decay_all=0,\n","    **kwargs\n","):\n","\n","    # build NIMA model and load existing weights if they were provided in config\n","    nima = Nima(\n","        base_model_name, n_classes, learning_rate_dense, dropout_rate, decay=decay_dense\n","    )\n","    nima.build()\n","\n","    if existing_weights is not None:\n","        nima.nima_model.load_weights(existing_weights)\n","\n","    # split samples in train and validation set, and initialize data generators\n","    samples_train, samples_test = train_test_split(\n","        samples, test_size=0.05, shuffle=True, random_state=10207\n","    )\n","\n","    training_generator = TrainDataGenerator(\n","        samples_train,\n","        image_dir,\n","        batch_size,\n","        n_classes,\n","        nima.preprocessing_function(),\n","        img_format=img_format,\n","    )\n","\n","    validation_generator = TestDataGenerator(\n","        samples_test,\n","        image_dir,\n","        batch_size,\n","        n_classes,\n","        nima.preprocessing_function(),\n","        img_format=img_format,\n","    )\n","\n","    # initialize callbacks TensorBoard and ModelCheckpoint\n","    tensorboard = TensorBoard(\n","        log_dir=log_dir, update_freq='batch'\n","    )\n","\n","    model_save_name = (\n","        'weights_' + base_model_name.lower() + '_{epoch:02d}_{val_loss:.3f}.hdf5'\n","    )\n","    model_file_path = os.path.join(weights_dir, model_save_name)\n","    model_checkpointer = ModelCheckpoint(\n","        filepath=model_file_path,\n","        monitor='val_loss',\n","        verbose=1,\n","        save_best_only=True,\n","        save_weights_only=True,\n","    )\n","\n","    # start training only dense layers\n","    # freeze\n","    for layer in nima.base_model.layers:\n","        layer.trainable = False\n","\n","    nima.compile()\n","    nima.nima_model.summary()\n","\n","    nima.nima_model.fit_generator(\n","        generator=training_generator,\n","        validation_data=validation_generator,\n","        epochs=epochs_train_dense,\n","        verbose=1,\n","        use_multiprocessing=multiprocessing_data_load,\n","        workers=num_workers_data_load,\n","        max_queue_size=30,\n","        callbacks=[tensorboard, model_checkpointer],\n","    )\n","\n","################################################################################\n","\n","    # start training all layers\n","    for layer in nima.base_model.layers:\n","        layer.trainable = True\n","\n","    nima.learning_rate = learning_rate_all\n","    nima.decay = decay_all\n","    nima.compile()\n","    nima.nima_model.summary()\n","\n","    nima.nima_model.fit_generator(\n","        generator=training_generator,\n","        validation_data=validation_generator,\n","        epochs=epochs_train_dense + epochs_train_all,\n","        initial_epoch=epochs_train_dense,\n","        verbose=1,\n","        use_multiprocessing=multiprocessing_data_load,\n","        workers=num_workers_data_load,\n","        max_queue_size=30,\n","        callbacks=[tensorboard, model_checkpointer],\n","    )\n","\n","    K.clear_session()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-HOMEEc5SPWW","colab_type":"text"},"source":["# Call for Train"]},{"cell_type":"code","metadata":{"id":"QomfpfUiUArI","colab_type":"code","colab":{}},"source":["IMAGE_DIR = '/content/gdrive/My Drive/TID2013/distorted_images'\n","\n","WEIGHTS_DIR = '/content/gdrive/My Drive/GC-IQA_Prism/IQA_Prism/weights/E1'\n","LOG_DIR = '/content/gdrive/My Drive/GC-IQA_Prism/IQA_Prism/logs/E1'\n","ensure_dir_exists(WEIGHTS_DIR)\n","ensure_dir_exists(LOG_DIR)\n","\n","CONFIG_DIR = '/content/gdrive/My Drive/GC-IQA_Prism/IQA_Prism/config'\n","CONFIG_FILE = os.path.join(CONFIG_DIR, 'config_technical_gpu.json')\n","config = load_config(CONFIG_FILE)\n","\n","SAMPLES_DIR = '/content/gdrive/My Drive/GC-IQA_Prism/IQA_Prism/labels/TID2013'\n","SAMPLES_FILE = os.path.join(SAMPLES_DIR, 'tid_labels_train.json')\n","samples = load_samples(SAMPLES_FILE)\n","\n","train(samples=samples, weights_dir=WEIGHTS_DIR, log_dir=LOG_DIR, image_dir=IMAGE_DIR, **config)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"341c7y43SBED","colab_type":"text"},"source":["# Predict"]},{"cell_type":"code","metadata":{"id":"EFOILpc1SN4x","colab_type":"code","colab":{}},"source":["def image_file_to_json(img_path):\n","    img_dir = os.path.dirname(img_path)\n","    img_id = os.path.basename(img_path).split('.')[0]\n","\n","    return img_dir, [{'image_id': img_id}]\n","\n","\n","def image_dir_to_json(img_dir, img_type='jpg'):\n","    img_paths = glob.glob(os.path.join(img_dir, '*.'+img_type))\n","\n","    samples = []\n","    for img_path in img_paths:\n","        img_id = os.path.basename(img_path).split('.')[0]\n","        samples.append({'image_id': img_id})\n","\n","    return samples\n","\n","\n","def predict(base_model_name, weights_file, image_source, predictions_file, img_format='jpg'):\n","    # load samples\n","    if os.path.isfile(image_source):\n","        image_dir, samples = image_file_to_json(image_source)\n","    else:\n","        image_dir = image_source\n","        samples = image_dir_to_json(image_dir, img_type='jpg')\n","\n","    # build model and load weights\n","    nima = Nima(base_model_name, weights=None)\n","    nima.build()\n","    nima.nima_model.load_weights(weights_file)\n","\n","    # initialize data generator\n","    data_generator = TestDataGenerator(samples, image_dir, 64, 10, nima.preprocessing_function(),\n","                                       img_format=img_format)\n","\n","    # get predictions\n","    predictions = nima.nima_model.predict_generator(data_generator, workers=8, use_multiprocessing=True, verbose=1)\n","\n","    # calc mean scores and add to samples\n","    for i, sample in enumerate(samples):\n","        sample['mean_score_prediction'] = calc_mean_score(predictions[i])\n","\n","    print(json.dumps(samples, indent=2))\n","\n","    if predictions_file is not None:\n","        save_json(samples, predictions_file)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1U0Vql1HUJrW","colab_type":"text"},"source":["# Call for predict"]},{"cell_type":"code","metadata":{"id":"WBV7s-uiULhu","colab_type":"code","colab":{}},"source":["BASE_MODEL_NAME = \"MobileNet\"\n","WEIGHTS_FILE = '/content/gdrive/My Drive/GC-IQA_Prism/IQA_Prism/weights/E1/weights_mobilenet_50_0.074.hdf5'\n","IMAGE_SOURCE = '/content/gdrive/My Drive/GC-IQA_Prism/IQA_Prism/test_images'\n","PREDICTIONS_FILE = '/content/gdrive/My Drive/GC-IQA_Prism/IQA_Prism/predictions/E1.json'\n","\n","ensure_file_exists(PREDICTIONS_FILE)\n","\n","predict(base_model_name=BASE_MODEL_NAME, weights_file=WEIGHTS_FILE, image_source=IMAGE_SOURCE, predictions_file=PREDICTIONS_FILE)"],"execution_count":0,"outputs":[]}]}